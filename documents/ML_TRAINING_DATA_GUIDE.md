# ML Training Data Collection Guide

**Last Updated:** 2025-11-02  
**Status:** Ready for Production

---

## Quick Start

### **Recommended: One-Command Collection**

```bash
# RECOMMENDED: Large dataset for good model accuracy
python scripts/collect_ml_training_data_full.py --large
```

This will:
1. Fetch all NSE stocks
2. Run backtests on 200 stocks over 10 years
3. Extract features and create training dataset
4. Generate ~10,000+ training examples

**Estimated Time:** ~7-10 minutes

---

## Collection Options

### **Preset Modes (Recommended)**

| Mode | Command | Stocks | Years | Examples | Time | Best For |
|------|---------|--------|-------|----------|------|----------|
| **Quick Test** | `--quick-test` | 10 | 2 | ~50 | 30s | Testing pipeline |
| **Small** | `--small` | 50 | 3 | ~500 | 2min | Quick iteration |
| **Medium** | `--medium` | 100 | 5 | ~2,000 | 4min | Initial training |
| **Large** â­ | `--large` | 200 | 10 | ~10,000 | 8min | **Production (Recommended)** |
| **Maximum** | Custom | 500 | 25 | ~50,000+ | 30min+ | Best accuracy |

### **Examples**

```bash
# Quick test (30 seconds)
python scripts/collect_ml_training_data_full.py --quick-test

# Small dataset (2 minutes)
python scripts/collect_ml_training_data_full.py --small

# Medium dataset (4 minutes)
python scripts/collect_ml_training_data_full.py --medium

# Large dataset - RECOMMENDED (8 minutes)
python scripts/collect_ml_training_data_full.py --large

# Custom: 150 stocks, 7 years
python scripts/collect_ml_training_data_full.py --max-stocks 150 --years-back 7

# Maximum dataset (30+ minutes)
python scripts/collect_ml_training_data_full.py --max-stocks 500 --years-back 25
```

---

## Manual Step-by-Step (Alternative)

If you prefer manual control:

### **Step 1: Get NSE Stocks**
```bash
python scripts/get_all_nse_stocks.py --output data/all_nse_stocks.txt
```

### **Step 2: Run Bulk Backtest**
```bash
# Small dataset
python scripts/bulk_backtest_all_stocks.py \
  --stocks-file data/all_nse_stocks.txt \
  --output data/backtest_training_data.csv \
  --max-stocks 50 \
  --years-back 3

# Large dataset (RECOMMENDED)
python scripts/bulk_backtest_all_stocks.py \
  --stocks-file data/all_nse_stocks.txt \
  --output data/backtest_training_data.csv \
  --max-stocks 200 \
  --years-back 10
```

### **Step 3: Extract Training Features**
```bash
python scripts/collect_training_data.py \
  --backtest-file data/backtest_training_data.csv \
  --output data/ml_training_data.csv
```

### **Step 4: Train Model**
```bash
python scripts/train_ml_model.py \
  --training-file data/ml_training_data.csv \
  --model-type random_forest
```

---

## Data Availability

### **yfinance Historical Data**

| Metric | Value |
|--------|-------|
| **Available Years** | Up to **30 years** (1996-2025) |
| **NSE Stocks** | 1,500+ available |
| **Large-cap Stocks** | ~30 years of data |
| **Mid/Small-cap** | 15-25 years typically |
| **Daily Trading Days** | ~250 per year |

### **Fetch Performance**

| # of Stocks | Time | Speed |
|-------------|------|-------|
| 10 stocks | 4s | 0.4s/stock |
| 50 stocks | 20s | ~0.3 min |
| 100 stocks | 41s | ~0.7 min |
| 200 stocks | 82s | ~1.4 min |
| 500 stocks | 205s | ~3.4 min |

---

## Output Files

### **Files Created**

1. **all_nse_stocks.txt** - List of all NSE stocks (1 per line)
2. **backtest_training_data_YYYYMMDD_HHMMSS.csv** - Backtest results with positions
3. **ml_training_data_YYYYMMDD_HHMMSS.csv** - Feature-engineered training dataset

### **Training Data Format**

**24 Features per Example:**
- Technical: `rsi_10`, `ema200`, `price`, `price_above_ema200`
- Volume: `volume`, `avg_volume_20`, `volume_ratio`, `vol_strong`
- Price Action: `recent_high_20`, `recent_low_20`, `support_distance_pct`
- Patterns: `has_hammer`, `has_bullish_engulfing`, `has_divergence`
- Fundamentals: `pe`, `pb`, `fundamental_ok`
- Meta: `ticker`, `entry_date`, `exit_date`

**Labels:**
- `strong_buy` - Gain >= 10%
- `buy` - Gain 5-10%
- `watch` - Gain 0-5%
- `avoid` - Loss < 0%

---

## Troubleshooting

### **Issue: "Not enough training examples"**

**Solution:** Increase `--max-stocks` or `--years-back`

```bash
# Instead of default
python scripts/collect_ml_training_data_full.py --small

# Try larger dataset
python scripts/collect_ml_training_data_full.py --large
```

### **Issue: "Stratification failed - only 1 member"**

**Cause:** Insufficient examples in one class (e.g., only 1 "avoid" example)

**Solution:** Already fixed in `ml_training_service.py` - stratification is auto-disabled when needed

### **Issue: "Feature extraction failed"**

**Cause:** Fixed in recent update - check that you have the latest `collect_training_data.py`

**Verification:**
```bash
# Should work now
python scripts/collect_training_data.py \
  --backtest-file data/backtest_training_data.csv \
  --output data/ml_training_data.csv
```

---

## Best Practices

### **For Model Training**

1. **Minimum Dataset Size:** 500+ examples
2. **Recommended Dataset Size:** 2,000-10,000 examples
3. **Class Balance:** Try to get similar numbers of each label
4. **Time Range:** 5-10 years captures various market conditions

### **Iterative Improvement**

```bash
# Start with quick test
python scripts/collect_ml_training_data_full.py --quick-test

# If looks good, scale up
python scripts/collect_ml_training_data_full.py --medium

# For production
python scripts/collect_ml_training_data_full.py --large
```

### **Production Workflow**

```bash
# 1. Collect large dataset (once)
python scripts/collect_ml_training_data_full.py --large

# 2. Train model
python scripts/train_ml_model.py \
  --training-file data/ml_training_data_TIMESTAMP.csv \
  --model-type random_forest

# 3. Model is automatically saved to models/
# 4. Use in production - ML verdicts will appear in Telegram notifications
```

---

## Expected Results

### **Small Dataset (50 stocks, 3 years)**
- Examples: ~500
- Training time: ~10 seconds
- Model accuracy: 60-75% (may overfit)

### **Medium Dataset (100 stocks, 5 years)**
- Examples: ~2,000
- Training time: ~30 seconds
- Model accuracy: 70-80%

### **Large Dataset (200 stocks, 10 years)** â­ RECOMMENDED
- Examples: ~10,000
- Training time: ~1-2 minutes
- Model accuracy: 75-85% (good generalization)

### **Maximum Dataset (500 stocks, 25 years)**
- Examples: ~50,000+
- Training time: ~5-10 minutes
- Model accuracy: 80-90% (best performance)

---

## Next Steps After Collection

### **1. Train the Model**
```bash
python scripts/train_ml_model.py \
  --training-file data/ml_training_data_TIMESTAMP.csv \
  --model-type random_forest
```

### **2. Verify Model Saved**
```bash
ls models/verdict_model_random_forest.pkl
ls models/verdict_model_features_random_forest.txt
```

### **3. Test ML Predictions**
ML predictions will automatically appear in:
- Telegram notifications
- Analysis results
- Console output

### **4. Monitor Performance**
- Track ML verdict accuracy vs actual outcomes
- Retrain periodically (monthly/quarterly) with new data
- Adjust features based on feature importance

---

## Advanced: Continuous Improvement

### **Monthly Retraining**

```bash
# Collect fresh data with recent market conditions
python scripts/collect_ml_training_data_full.py --large

# Retrain with new data
python scripts/train_ml_model.py \
  --training-file data/ml_training_data_LATEST.csv \
  --model-type random_forest

# Old model is automatically replaced
```

### **Feature Engineering**

Add new features in `scripts/collect_training_data.py`:
- More technical indicators (MACD, Bollinger Bands)
- Sector information
- Market cap data
- Volatility metrics

### **Model Tuning**

Try different models:
```bash
# Random Forest (current)
python scripts/train_ml_model.py --model-type random_forest

# XGBoost (if installed)
pip install xgboost
python scripts/train_ml_model.py --model-type xgboost
```

---

## Summary

**Quickest Path to Production ML:**

```bash
# One command - 8 minutes - 10,000+ examples
python scripts/collect_ml_training_data_full.py --large

# Train model - 1 minute
python scripts/train_ml_model.py \
  --training-file data/ml_training_data_*.csv \
  --model-type random_forest

# Done! ML verdicts now available in production
```

**Total Time:** ~10 minutes from zero to ML-powered trading signals! ðŸš€

<citations>
<document>
<document_type>RULE</document_type>
<document_id>vbKqp5FQjm8BcaAx6Lon2z</document_id>
</document>
</citations>
